{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-assisted Data Transformation for CHECK-IN\n",
    "This notebook helps you streamline your data transformation to the CHECK-IN data format using an AI assistant. We provide a prompt template that guides a chatbot (like ChatGPT, GitHub Copilot, or Gemini) to write the necessary Python code for you, saving you from having to learn the specific format requirements.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "- **Use the Prompt Template**: Copy the content of [notebooks/prompt_templates/PromptTemplate.docx](notebooks/prompt_templates/PromptTemplate.docx) and paste it into the AI chatbot of your choice.\n",
    "\n",
    "- **Provide Metadata**: The chatbot will start an interactive dialogue. Follow its instructions to provide the required metadata (file and column names). The prompt is designed to work without needing your actual data content.\n",
    "\n",
    "- **Review the Generated Code:** Treat the Python script from the chatbot as a draft and check it for accuracy, security and compliance with your internal policies.\n",
    "\n",
    "- **Execute the Code**: Paste the validated script into the next cell and run it.\n",
    "\n",
    "### Important Considerations\n",
    "\n",
    "- **Third-Party Service**: Please be aware that by using an external chatbot, you are interacting with a third-party service outside the futureEXPERT environment.\n",
    "\n",
    "- **Confidentiality**: If your metadata (file or column names) is confidential, use a company-approved, private AI system.\n",
    "\n",
    "- **Your Responsibility**: You are solely responsible for any prompts you share and for the code you execute. By using this template, you agree that our organisation accepts no liability for the output generated by third-party AI services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paste your code snippet here\n",
    "Example generated by ChatGPT4o: \n",
    "Replace when using own code snippet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load input CSV files with specified delimiter and decimal\n",
    "ordr = pd.read_csv(\"../example_data/ORDR.csv\", delimiter=',', decimal='.')\n",
    "itm = pd.read_csv(\"../example_data/OITM.csv\", delimiter=',', decimal='.')\n",
    "\n",
    "# Step 2: Join ORDR (left) with ITM (inner) on 'ArtikelNr'\n",
    "df = pd.merge(ordr, itm, how='left', on='ArtikelNr')\n",
    "\n",
    "# Step 3: Construct a proper datetime column from LieferdatumPositionTag, LieferdatumPositionMonat, LieferdatumPositionJahr\n",
    "df['Date'] = pd.to_datetime(df[['LieferdatumPositionJahr', 'LieferdatumPositionMonat', 'LieferdatumPositionTag']].rename(\n",
    "    columns={\n",
    "        'LieferdatumPositionJahr': 'year',\n",
    "        'LieferdatumPositionMonat': 'month',\n",
    "        'LieferdatumPositionTag': 'day'\n",
    "    }\n",
    "), errors='coerce')\n",
    "\n",
    "# Step 4: Select columns to keep for final output\n",
    "final_cols = ['Date', 'Menge', 'ArtikelGruppe', 'ArtikelBez']\n",
    "output_df = df[final_cols]\n",
    "\n",
    "# Optional: Drop rows with missing Date or Menge\n",
    "output_df = output_df.dropna(subset=['Date', 'Menge'])\n",
    "\n",
    "# Step 5: Export to CSV with defaults: comma delimiter, period decimal\n",
    "output_df.to_csv(\"prepared_timeseries.csv\", index=False)\n",
    "\n",
    "# Explanation:\n",
    "# - This script reads your two CSV files with proper parsing.\n",
    "# - Joins them on 'ArtikelNr'.\n",
    "# - Creates a single 'Date' column by combining year, month, day.\n",
    "# - Keeps your target column 'Menge' and extra columns 'ArtikelGruppe' and 'ArtikelBez'.\n",
    "# - Outputs the prepared file as 'prepared_timeseries.csv' ready for timeseries forecasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing your dataset, we connect to the client using our future username and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:futureexpert.expert_client:Successfully logged in for group group-expert.\n"
     ]
    }
   ],
   "source": [
    "from futureexpert import (DataDefinition,\n",
    "                          ExpertClient,\n",
    "                          FileSpecification,\n",
    "                          TsCreationConfig)\n",
    "import futureexpert.checkin as checkin\n",
    "\n",
    "client = ExpertClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *CHECK-IN* Configuration\n",
    "\n",
    "Now, letâ€™s use *CHECK-IN* to transform our data and upload the resulting time series to our database. We define the location of the CSV file and its specifications (`separator`, `decimal`). For our use case, we need to consider the following settings:\n",
    "- The data contains some missing values, which are equivalent to 'no demand' observations. Therefore, we set the `missing_value_handler` to `setToZero`.\n",
    "- Material `Hydraulikpumpe HYP-201` is an article that is no longer sold but is still part of the dataset. We do not need any forecasts for this material, so we can set a corresponding `FilterSettings`.\n",
    "- The columns ArtikelGruppe and ArtikelBez contain structural information about the data, so we define them as `GroupColumns`. For this use case, however, we only want to create forecasts at the material level, so we set that column as the `grouping_level` in the `TsCreationConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:futureexpert.expert_client:Transforming input data...\n",
      "INFO:futureexpert.expert_client:Creating time series using CHECK-IN...\n",
      "INFO:futureexpert.expert_client:Finished time series creation.\n"
     ]
    }
   ],
   "source": [
    "actuals_version_id = client.check_in_time_series(raw_data_source='prepared_timeseries.csv',\n",
    "                                                  file_specification=FileSpecification(delimiter=',', decimal='.'),\n",
    "                                                  data_definition=DataDefinition(date_columns=checkin.DateColumn(name='Date', format='%Y-%m-%d', name_new='Date'),\n",
    "                                                                                 value_columns=[checkin.ValueColumn(name='Menge', name_new='Menge')],\n",
    "                                                                                 group_columns=[checkin.GroupColumn(name='ArtikelGruppe', name_new='ArtikelGruppe'),\n",
    "                                                                                                checkin.GroupColumn(name='ArtikelBez', name_new='ArtikelBez')]),\n",
    "                                                  config_ts_creation=TsCreationConfig(time_granularity='monthly',\n",
    "                                                                                      start_date='2007-10-01',\n",
    "                                                                                      end_date='2024-06-01',\n",
    "                                                                                      value_columns_to_save=['Menge'],\n",
    "                                                                                      grouping_level=['ArtikelBez'],\n",
    "                                                                                      missing_value_handler='setToZero',\n",
    "                                                                                      filter=[checkin.FilterSettings(type='exclusion', variable='ArtikelBez', items=['Hydraulikpumpe HYP-201'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "You've successfully created and checked in your new data file. It contains a date column, one or more value columns, and any optional grouping or additional columns you included.\n",
    "\n",
    "You can now use the ``actuals_version_id`` to continue with your forecast. For further guidance, please use our templates, such as the [Getting-Started-Notebook](getting_started.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
