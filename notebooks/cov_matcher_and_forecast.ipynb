{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _MATCHER_ via _EXPERT_\n",
    "The _MATCHER_ module ranks a given set of covariates according to their predictive power. First, for each covariate, it determines the best lag (time shift) for every forecasting object. Then, _MATCHER_ evaluates the predictive power of the models including one of the covariates against the benchmark model, which does not use any covariates.\n",
    "## Requirements\n",
    "To generate results with _MATCHER_, the data must meet the following conditions. If the data is not suitable, you will receive appropriate feedback.\n",
    "- All covariates and the forecasting object share the same granularity.\n",
    "- No missing values in the forecasting object or the covariates.\n",
    "- The forecasting object has at least 78 data points.\n",
    "- All covariates have at least 96 data points.\n",
    "- A single file or data frame contains all covariates.\n",
    "\n",
    "\n",
    "This notebook includes an example with daily data. For another example using monthly data, see [cov_matcher_and_forecast_monthly](notebooks/cov_matcher_and_forecast_monthly.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from futureexpert import (DataDefinition,\n",
    "                          ExpertClient,\n",
    "                          FileSpecification,\n",
    "                          ForecastingConfig,\n",
    "                          MatcherConfig,\n",
    "                          MethodSelectionConfig,\n",
    "                          ReportConfig,\n",
    "                          TsCreationConfig)\n",
    "\n",
    "client = ExpertClient(user='', password='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps\n",
    "Data versions must be created using _CHECK-IN_ for both the covariates and the time series for which a prediction will be calculated later.\n",
    "\n",
    "Particular care must be taken here to ensure that the same granularity is selected for all data. If desired, you can already define here whether missing values should be replaced by 0.\n",
    " \n",
    "See the notebook [Getting Started](getting_started.ipynb) for more details on how to configure _CHECK-IN_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import futureexpert.checkin as checkin\n",
    "\n",
    "# Check in covariates\n",
    "covs_check_in_results = client.check_in_time_series(raw_data_source='../example_data/working_days_bavaria.csv',\n",
    "                                                    data_definition=DataDefinition(date_columns=checkin.DateColumn(name='time', format='%Y-%m-%d'),\n",
    "                                                                                   value_columns=[checkin.ValueColumn(name='value')]),\n",
    "                                                    config_ts_creation=TsCreationConfig(time_granularity='daily',\n",
    "                                                                                        value_columns_to_save=['value']),\n",
    "                                                    file_specification=FileSpecification(delimiter=';', decimal=','))\n",
    "\n",
    "# Check in forecasting object\n",
    "ts_check_in_results = client.check_in_time_series(raw_data_source='../example_data/bicycle_data_single.csv',\n",
    "                                                  data_definition=DataDefinition(date_columns=checkin.DateColumn(name='date', format='%Y-%m-%d'),\n",
    "                                                                                 value_columns=[checkin.ValueColumn(name='value')]),\n",
    "                                                  config_ts_creation=TsCreationConfig(time_granularity='daily',\n",
    "                                                                                      value_columns_to_save=['value']),\n",
    "                                                  file_specification=FileSpecification(delimiter=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure _MATCHER_\n",
    "The two versions of covariates and forecasting object must be specified for the _MATCHER_ report. A name can also be created for the report.\n",
    "Furthermore, `min_lag` and `max_lag` can be defined. These are used to control which time shifts are to be tested. The following default values are tested for the different granularities if no values have been defined:\n",
    "\n",
    "- monthly: -2 to 6\n",
    "- daily: -2 to 4\n",
    "- weekly, hourly and halfhourly : -2 to 12\n",
    "- quarter: -2 to 2\n",
    "- yearly: -2 to 1\n",
    "\n",
    "In some cases, results cannot be calculated for all lags. When this happens, only a subset of these lags are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_matcher = MatcherConfig(title='Covariate MATCHER started with EXPERT',\n",
    "                               actuals_version=ts_check_in_results.version_id,\n",
    "                               covs_versions=[covs_check_in_results.version_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start _MATCHER_\n",
    "Once the report has been defined, _MATCHER_ can be started. It might take a few minutes before the results are available, the current status can be accessed with `get_report_status()`.\n",
    "Possible errors that may occur during the calculation:\n",
    "- Covariates contain missing values. The affected covariates are listed in the error message. If this error occurs, you should check whether the granularity has been set correctly (e.g. daily instead of monthly data). If there are still missing values in the data, they can be replaced by 0s during _CHECK-IN_. Alternatively, individual covariates can also be completely removed by setting appropriate filters at _CHECK-IN_.\n",
    "- The status *no evaluation* is returned for one or more time series. In this case, some requirement for the data is not met. You will find more information on that in the status description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_identifier = client.start_matcher(config=config_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Watch the current status of the matcher report\n",
    "while not (current_status := client.get_report_status(id=matcher_identifier)).is_finished:\n",
    "    current_status.print()\n",
    "    print('Waiting another 30 seconds to finish matcher...')\n",
    "    time.sleep(30)  # Wait between status requests\n",
    "\n",
    "current_status.print()\n",
    "\n",
    "matcher_results = client.get_matcher_results(matcher_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results\n",
    "Results can be inspected via the results object. You can find the ranking of all predictive covariates based on their respective predictive power for each time series.  The covariate with rank 1 is the covariate (or indicator) with the strongest predictive power for the forecasting object. Covariates with a higher rank than the benchmark model without any covariates have predictive power for the forecasting object, while covariates with a lower rank do not explain the forecasting object. Non-leading indicators will not appear in the results.\n",
    "\n",
    "The indicator ranking (result of _MATCHER_) can be used as input for _FORECAST_. A forecast will be generated for every indicator in the ranking using a suitable method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts_result in matcher_results:\n",
    "    for r in ts_result.ranking:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from futureexpert import plot\n",
    "\n",
    "for ts_result in matcher_results:\n",
    "    for model_rank in ts_result.ranking:\n",
    "        if model_rank.covariates:\n",
    "            plot.plot_time_series(ts_result.actuals, covariate= model_rank.covariates[0],plot_last_x_data_points_only=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you want to adjust the results before forecasting? (optional)\n",
    "If you want to adjust the results before forecasting, you convert the _MATCHER_ ranking to a covariate configuration for _FORECAST_ locally instead of just referencing the report ID of the _MATCHER_ result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_config = [res.convert_ranking_to_forecast_config() for res in matcher_results]\n",
    "covs_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adjust the results either before or after this conversion:\n",
    "\n",
    "1. Directly adjust the list obtained from get_matcher_results. e.g remove covariates or change lags.\n",
    "2. Adjust the configuration after converting the results to the format needed for the forecast.\n",
    "\n",
    "To use the adjusted results in your forecast run, use the parameter `covs_configuration` and unset the parameter `matcher_report_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start forecast\n",
    "Specify the id of the _MATCHER_ report in the forecasting configuration. A lag no longer needs to be defined; the necessary information is taken from the _MATCHER_ result. For the seven best covariates, an individual model is created. Which covariate is used in a model is indicated in the model name.\n",
    "\n",
    "\n",
    "If you want to create forecasts with manually chosen lags, check the documentation in the notebook [forecasts_with_covariates](notebooks/forecast_with_covariates.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_report_config = ReportConfig(title='Test fc with cov selection',\n",
    "                                forecasting=ForecastingConfig(fc_horizon=10),\n",
    "                                method_selection=MethodSelectionConfig(number_iterations=6),\n",
    "                                matcher_report_id=matcher_identifier.report_id,\n",
    "                                covs_versions=[covs_check_in_results.version_id])\n",
    "\n",
    "forecast_identifier = client.start_forecast(version=ts_check_in_results.version_id, config=fc_report_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the current status of the forecasting report\n",
    "while not (current_status := client.get_report_status(id=forecast_identifier)).is_finished:\n",
    "    current_status.print()\n",
    "    print('Waiting another 30 seconds to finish forecasting...')\n",
    "    time.sleep(30)  # Wait between status requests\n",
    "\n",
    "current_status.print()\n",
    "\n",
    "# Retrieve the final results\n",
    "results = client.get_fc_results(id=forecast_identifier, include_backtesting=True, include_k_best_models=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check used covariates\n",
    "For every model of every forecasted time series, check which indicator was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts_result in results:\n",
    "    for model in ts_result.models:\n",
    "        print(f'{model.model_name}({model.model_selection.ranking}): {model.covariates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use combination of _MATCHER_ and _FORECAST_ ranking\n",
    "\n",
    "An alterantive ranking can be created using the function `replace_ranking_with_matcher_ranking`. In the result the _MATCHER_ ranking has priority over the _FORECAST_ ranking. For the none-covariate model only the best none-covariten model from the _FORECAST_ run is added to the ranking next to all covariate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import futureexpert.forecast\n",
    "new_ranked_results = futureexpert.forecast.combine_forecast_ranking_with_matcher_ranking(forecast_results=results, matcher_results=matcher_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts_result in new_ranked_results:\n",
    "    for model in ts_result.models:\n",
    "        print(f'{model.model_name}({model.model_selection.ranking}): {model.covariates}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
